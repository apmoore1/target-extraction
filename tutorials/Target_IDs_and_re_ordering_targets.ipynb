{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Target IDs and re-ordering targets.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/apmoore1/target-extraction/blob/master/tutorials/Target_IDs_and_re_ordering_targets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OR7qvUIqdwFi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "!pip install -U git+git://github.com/apmoore1/target-extraction.git@master#egg=target-extraction"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u9zPDFkmd9HH",
        "colab_type": "text"
      },
      "source": [
        "# Target IDs, re-ordering targets, and combining on data on IDs\n",
        "\n",
        "In this tutorial we will show you how to:\n",
        "1. create unique IDs at the target level but the methods used here can generalise to other attributes like aspects.\n",
        "2. Re-oder a dataset so that the target attributes are ordered based on when they occur in the text. This is useful for methods that assume the targets are ordered e.g. [Hazarika et al. 2018](https://www.aclweb.org/anthology/N18-2043.pdf) inter aspect/target neural network. \n",
        "3. Combining data from one dataset into another based on the target ID from point 1.\n",
        "\n",
        "The reason why you might want to save and create unique target or aspect ID's is so that your work can be shared with others knowing, that each prediction on a target or aspect has a unique identifier.\n",
        "\n",
        "To demonstrate all of the above we are going to use the training split from the Election Twitter dataset from [Wang et al. 2017](https://www.aclweb.org/anthology/E17-1046.pdf) as this can easily be downloaded as shown below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ATapp3MpfVq9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from target_extraction.dataset_parsers import wang_2017_election_twitter_train\n",
        "\n",
        "dataset = wang_2017_election_twitter_train()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6EzZnEywhKXa",
        "colab_type": "text"
      },
      "source": [
        "## Create Unique IDs\n",
        "So we have a dataset and below we print one target text object which contains three targets (`Police`, `crime`, and `Conservatives`). However the only unique identifier in this target object is the `text_id` key which uniquely identifies this one target object but none of the targets (or categories if they existed in the dataset)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ZvF5b_ahAfc",
        "colab_type": "code",
        "outputId": "5ead15af-f944-4016-a0e1-935c1c9bd570",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "target_object = next(dataset.dict_iterator())\n",
        "target_object"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'categories': None,\n",
              " 'category_sentiments': None,\n",
              " 'spans': [Span(start=22, end=28),\n",
              "  Span(start=49, end=54),\n",
              "  Span(start=0, end=13)],\n",
              " 'target_sentiments': ['neutral', 'positive', 'neutral'],\n",
              " 'targets': ['Police', 'crime', 'Conservatives'],\n",
              " 'text': 'Conservatives cut the Police budget and this cut crime! Maybe not... #spin #BattleForNumber10',\n",
              " 'text_id': '81207500663427072'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43kVbRk0hna1",
        "colab_type": "text"
      },
      "source": [
        "Therefore we can add unique identifiers for the targets using the:\n",
        "`add_unique_key` function which has two arguments:\n",
        "1. The key that you want to uniquely identify in our case this is the `target` key.\n",
        "2. The name of the key that will store the unique identifiers e.g. `target_ids`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKUB3sYwhItM",
        "colab_type": "code",
        "outputId": "92df4aba-8875-4c06-d2ce-cb2cd3313197",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "dataset.add_unique_key('targets', 'target_ids')\n",
        "target_object = next(dataset.dict_iterator())\n",
        "target_object"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'categories': None,\n",
              " 'category_sentiments': None,\n",
              " 'spans': [Span(start=22, end=28),\n",
              "  Span(start=49, end=54),\n",
              "  Span(start=0, end=13)],\n",
              " 'target_ids': ['81207500663427072::0',\n",
              "  '81207500663427072::1',\n",
              "  '81207500663427072::2'],\n",
              " 'target_sentiments': ['neutral', 'positive', 'neutral'],\n",
              " 'targets': ['Police', 'crime', 'Conservatives'],\n",
              " 'text': 'Conservatives cut the Police budget and this cut crime! Maybe not... #spin #BattleForNumber10',\n",
              " 'text_id': '81207500663427072'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNuujH-Uh-eI",
        "colab_type": "text"
      },
      "source": [
        "We can see now that we have a new field `target_ids` which are unique identifiers for the `targets` key. Furthermore we can see that the unique ids are generated by combining the `text_id` value with a delimiter (by default this is `::`) and then the index of the value we are creating ids for.\n",
        "\n",
        "If you want to use a different `delimiter` this can be easily done as shown below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKAWdhwJh9KN",
        "colab_type": "code",
        "outputId": "499b14b1-907b-4244-8ee0-26aca5c9ab80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "# need to delete the current target_id field before adding it again:\n",
        "for value in dataset.values():\n",
        "  del value['target_ids']\n",
        "dataset.add_unique_key('targets', 'target_ids', id_delimiter='$$')\n",
        "target_object = next(dataset.dict_iterator())\n",
        "target_object"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'categories': None,\n",
              " 'category_sentiments': None,\n",
              " 'spans': [Span(start=22, end=28),\n",
              "  Span(start=49, end=54),\n",
              "  Span(start=0, end=13)],\n",
              " 'target_ids': ['81207500663427072$$0',\n",
              "  '81207500663427072$$1',\n",
              "  '81207500663427072$$2'],\n",
              " 'target_sentiments': ['neutral', 'positive', 'neutral'],\n",
              " 'targets': ['Police', 'crime', 'Conservatives'],\n",
              " 'text': 'Conservatives cut the Police budget and this cut crime! Maybe not... #spin #BattleForNumber10',\n",
              " 'text_id': '81207500663427072'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upK10BSakeRc",
        "colab_type": "text"
      },
      "source": [
        "## Re-ordering\n",
        "\n",
        "As we can see from the example above the targets are not in order as in the targets are not in a left to right order when they appear in the text (`Conservatives` is the last target in the `targets` list but it is the first target shown in the text).\n",
        "\n",
        "Some methods assume that the data they are feed are in this left to right order e.g. [Hazarika et al. 2018](https://www.aclweb.org/anthology/N18-2043.pdf) method which uses a LSTM to encode the inter aspect/target representations.\n",
        "\n",
        "Thus sometimes we need to re-order the data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7zFt45bQjWme",
        "colab_type": "code",
        "outputId": "0930da6e-9f0b-4290-a1c0-2b0b10d1442f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "dataset.re_order()\n",
        "target_object = next(dataset.dict_iterator())\n",
        "target_object"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'categories': None,\n",
              " 'category_sentiments': None,\n",
              " 'spans': [Span(start=0, end=13),\n",
              "  Span(start=22, end=28),\n",
              "  Span(start=49, end=54)],\n",
              " 'target_ids': ['81207500663427072$$2',\n",
              "  '81207500663427072$$0',\n",
              "  '81207500663427072$$1'],\n",
              " 'target_sentiments': ['neutral', 'neutral', 'positive'],\n",
              " 'targets': ['Conservatives', 'Police', 'crime'],\n",
              " 'text': 'Conservatives cut the Police budget and this cut crime! Maybe not... #spin #BattleForNumber10',\n",
              " 'text_id': '81207500663427072'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NOeapPAit4ZK",
        "colab_type": "text"
      },
      "source": [
        "As we can see the `targets` are now re-ordered along with all the other `List` keys like `target_sentiments`, `spans`, and `target_ids`. This is because when `re_order` is called it re-orders all `List` keys according to the `spans` key.\n",
        "\n",
        "If you do have some `List` fields that should not be re-ordered then this can be explicty taken into account through the `re_order` function. An example is shown below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oxjz1D4blm7Y",
        "colab_type": "code",
        "outputId": "f9490df0-466f-44c9-f46e-a63a9c3bda3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        }
      },
      "source": [
        "dataset.tokenize(str.split)\n",
        "target_object = next(dataset.dict_iterator())\n",
        "target_object"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'categories': None,\n",
              " 'category_sentiments': None,\n",
              " 'spans': [Span(start=0, end=13),\n",
              "  Span(start=22, end=28),\n",
              "  Span(start=49, end=54)],\n",
              " 'target_ids': ['81207500663427072$$2',\n",
              "  '81207500663427072$$0',\n",
              "  '81207500663427072$$1'],\n",
              " 'target_sentiments': ['neutral', 'neutral', 'positive'],\n",
              " 'targets': ['Conservatives', 'Police', 'crime'],\n",
              " 'text': 'Conservatives cut the Police budget and this cut crime! Maybe not... #spin #BattleForNumber10',\n",
              " 'text_id': '81207500663427072',\n",
              " 'tokenized_text': ['Conservatives',\n",
              "  'cut',\n",
              "  'the',\n",
              "  'Police',\n",
              "  'budget',\n",
              "  'and',\n",
              "  'this',\n",
              "  'cut',\n",
              "  'crime!',\n",
              "  'Maybe',\n",
              "  'not...',\n",
              "  '#spin',\n",
              "  '#BattleForNumber10']}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V7lIElJDum1B",
        "colab_type": "text"
      },
      "source": [
        "We now have a `List` key `tokenized_text` that is not associated to the `spans` key at all therefore if we are re-ordering this dataset we do not want to re-order `tokenized_text` field as this would result in the following error:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YpU_q6oEulnY",
        "colab_type": "code",
        "outputId": "99a09beb-8f3a-4526-b118-44a91aac52b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        }
      },
      "source": [
        "dataset.re_order()\n",
        "target_object = next(dataset.dict_iterator())\n",
        "target_object"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "Exception",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/target_extraction/data_types.py\u001b[0m in \u001b[0;36mre_order\u001b[0;34m(self, keys_not_to_order)\u001b[0m\n\u001b[1;32m   1170\u001b[0m                         \u001b[0msorted_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorting_by_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_order\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1171\u001b[0;31m                     \u001b[0;32massert\u001b[0m \u001b[0msorted_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1172\u001b[0m                     \u001b[0mnew_key_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-0d1368dbee84>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mre_order\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtarget_object\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdict_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtarget_object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/target_extraction/data_types.py\u001b[0m in \u001b[0;36mre_order\u001b[0;34m(self, keys_not_to_order)\u001b[0m\n\u001b[1;32m   2161\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2162\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself_copy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2163\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2165\u001b[0m     def add_unique_key(self, id_key: str, id_key_name: str, \n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/target_extraction/data_types.py\u001b[0m in \u001b[0;36mre_order\u001b[0;34m(self, keys_not_to_order)\u001b[0m\n\u001b[1;32m   2158\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2159\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mtarget_text\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2160\u001b[0;31m                 \u001b[0mtarget_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mre_order\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeys_not_to_order\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2161\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2162\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself_copy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/target_extraction/data_types.py\u001b[0m in \u001b[0;36mre_order\u001b[0;34m(self, keys_not_to_order)\u001b[0m\n\u001b[1;32m   1176\u001b[0m                            \u001b[0;34mf'following key {key} and value {value} for this '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m                            f'TargetText {self}')\n\u001b[0;32m-> 1178\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1179\u001b[0m         \u001b[0;31m# Covers the rollback problem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnew_key_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mException\u001b[0m: The following error Traceback (most recent call last):\n  File \"/usr/local/lib/python3.6/dist-packages/target_extraction/data_types.py\", line 1171, in re_order\n    assert sorted_value\nAssertionError\n has occured on the following key tokenized_text and value ['#BattleForNumber10', 'i', 'want', 'to', 'like', 'milliband', 'but', 'he', 'comes', 'across', 'like', 'a', 'drama', 'teacher', 'who', 'wants', 'me', 'to', 'pretend', \"I'm\", 'a', 'bowl', 'of', 'melons'] for this TargetText TargetText({'text': \"#BattleForNumber10 i want to like milliband but he comes across like a drama teacher who wants me to pretend I'm a bowl of melons\", 'text_id': '81212256144367616', 'targets': [], 'spans': [], 'target_sentiments': [], 'categories': None, 'category_sentiments': None, 'target_ids': [], 'tokenized_text': ['#BattleForNumber10', 'i', 'want', 'to', 'like', 'milliband', 'but', 'he', 'comes', 'across', 'like', 'a', 'drama', 'teacher', 'who', 'wants', 'me', 'to', 'pretend', \"I'm\", 'a', 'bowl', 'of', 'melons']})"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTbOWMPZxx47",
        "colab_type": "code",
        "outputId": "1d1c45a9-e462-4146-ce42-87727c3ac716",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        }
      },
      "source": [
        "target_object = next(dataset.dict_iterator())\n",
        "target_object"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'categories': None,\n",
              " 'category_sentiments': None,\n",
              " 'spans': [Span(start=0, end=13),\n",
              "  Span(start=22, end=28),\n",
              "  Span(start=49, end=54)],\n",
              " 'target_ids': ['81207500663427072$$2',\n",
              "  '81207500663427072$$0',\n",
              "  '81207500663427072$$1'],\n",
              " 'target_sentiments': ['neutral', 'neutral', 'positive'],\n",
              " 'targets': ['Conservatives', 'Police', 'crime'],\n",
              " 'text': 'Conservatives cut the Police budget and this cut crime! Maybe not... #spin #BattleForNumber10',\n",
              " 'text_id': '81207500663427072',\n",
              " 'tokenized_text': ['Conservatives',\n",
              "  'cut',\n",
              "  'the',\n",
              "  'Police',\n",
              "  'budget',\n",
              "  'and',\n",
              "  'this',\n",
              "  'cut',\n",
              "  'crime!',\n",
              "  'Maybe',\n",
              "  'not...',\n",
              "  '#spin',\n",
              "  '#BattleForNumber10']}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u01Ur7_HQIk-",
        "colab_type": "text"
      },
      "source": [
        "However as we can see above even though the error has occured nothing has changed to the dataset. \n",
        "\n",
        "To avoid such errors use the `keys_not_to_order` argument within the `re_order` function like below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQ86WP5YQluJ",
        "colab_type": "code",
        "outputId": "991eff30-034e-4cd0-d63b-4de415352c99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        }
      },
      "source": [
        "# Want to make sure it is a new un-ordered dataset\n",
        "dataset = wang_2017_election_twitter_train()\n",
        "dataset.tokenize(str.split)\n",
        "dataset.re_order(['tokenized_text'])\n",
        "target_object = next(dataset.dict_iterator())\n",
        "target_object"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'categories': None,\n",
              " 'category_sentiments': None,\n",
              " 'spans': [Span(start=0, end=13),\n",
              "  Span(start=22, end=28),\n",
              "  Span(start=49, end=54)],\n",
              " 'target_sentiments': ['neutral', 'neutral', 'positive'],\n",
              " 'targets': ['Conservatives', 'Police', 'crime'],\n",
              " 'text': 'Conservatives cut the Police budget and this cut crime! Maybe not... #spin #BattleForNumber10',\n",
              " 'text_id': '81207500663427072',\n",
              " 'tokenized_text': ['Conservatives',\n",
              "  'cut',\n",
              "  'the',\n",
              "  'Police',\n",
              "  'budget',\n",
              "  'and',\n",
              "  'this',\n",
              "  'cut',\n",
              "  'crime!',\n",
              "  'Maybe',\n",
              "  'not...',\n",
              "  '#spin',\n",
              "  '#BattleForNumber10']}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tq17GHzaRX51",
        "colab_type": "text"
      },
      "source": [
        "As we can see above no error and the targets have been re-ordered in the expected manner.\n",
        "\n",
        "## Combining data from two datasets using ID\n",
        "\n",
        "Now that we have these unique target ids we can use them to combine data from two dataset instances. This can be useful when `dataset_1` is re-ordered and `dataset_2` is not and both instances have prediction made from different models e.g. `model_1` and `model_2`. Below we create this setup, where `dataset_1` has predictions from `model_1` (all positive unless the target is `Conservatives` then negative) and `dataset_2` has predictions from `model_2` (all negative unless the target is `Conservatives` then positive):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3-vApx6Srsg",
        "colab_type": "code",
        "outputId": "6b6e7628-d3c8-4902-cdf3-fed388d0b4b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        }
      },
      "source": [
        "from target_extraction.data_types import TargetTextCollection\n",
        "from typing import Optional, List\n",
        "def add_fictional_predictions(dataset: TargetTextCollection, model_name: str, \n",
        "                              positive: bool, \n",
        "                              number_runs: Optional[int] = None) -> None:\n",
        "  def get_predictions(positive_default: bool, targets: List[str]) -> List[str]:\n",
        "    target_predictions = [] \n",
        "    for target in targets:\n",
        "      if positive_default and target != 'Conservatives':\n",
        "        target_predictions.append('positive')\n",
        "      elif positive_default and target == 'Conservatives':\n",
        "        target_predictions.append('negative')\n",
        "      elif not positive_default and target != 'Conservatives':\n",
        "        target_predictions.append('negative')\n",
        "      elif not positive_default and target == 'Conservatives':\n",
        "        target_predictions.append('positive')\n",
        "      else:\n",
        "        err = 'Fallen through all of the if statements in `get_prediction`'\n",
        "        raise ValueError(err)\n",
        "    return target_predictions\n",
        "\n",
        "  for target_text in dataset.values():\n",
        "    num_targets = len(target_text['targets'])\n",
        "    prediction_list = []\n",
        "    if number_runs is not None:\n",
        "      for run in range(number_runs):\n",
        "        prediction_list.append(get_predictions(positive, target_text['targets']))\n",
        "    else:\n",
        "      prediction_list = get_predictions(positive, target_text['targets'])\n",
        "    target_text[f'{model_name}_predictions'] = prediction_list\n",
        "\n",
        "dataset_1 = wang_2017_election_twitter_train()\n",
        "dataset_2 = wang_2017_election_twitter_train()\n",
        "# Add the unique target ids\n",
        "for dataset in [dataset_1, dataset_2]:\n",
        "  dataset.add_unique_key('targets', 'target_id')\n",
        "# re-order dataset_1\n",
        "dataset_1.re_order()\n",
        "# add predictions to datasets\n",
        "add_fictional_predictions(dataset_1, 'model_1', True)\n",
        "add_fictional_predictions(dataset_2, 'model_2', False)\n",
        "\n",
        "next(dataset_1.dict_iterator())"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'categories': None,\n",
              " 'category_sentiments': None,\n",
              " 'model_1_predictions': ['negative', 'positive', 'positive'],\n",
              " 'spans': [Span(start=0, end=13),\n",
              "  Span(start=22, end=28),\n",
              "  Span(start=49, end=54)],\n",
              " 'target_id': ['81207500663427072::2',\n",
              "  '81207500663427072::0',\n",
              "  '81207500663427072::1'],\n",
              " 'target_sentiments': ['neutral', 'neutral', 'positive'],\n",
              " 'targets': ['Conservatives', 'Police', 'crime'],\n",
              " 'text': 'Conservatives cut the Police budget and this cut crime! Maybe not... #spin #BattleForNumber10',\n",
              " 'text_id': '81207500663427072'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RSTcusCUTU_",
        "colab_type": "text"
      },
      "source": [
        "An example of samples from `dataset_1` is shown above and `dataset_2` below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A79nfbDKTIqV",
        "colab_type": "code",
        "outputId": "fe83d545-fecb-4095-d4ca-81198cb85fbc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        }
      },
      "source": [
        "next(dataset_2.dict_iterator())"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'categories': None,\n",
              " 'category_sentiments': None,\n",
              " 'model_2_predictions': ['negative', 'negative', 'positive'],\n",
              " 'spans': [Span(start=22, end=28),\n",
              "  Span(start=49, end=54),\n",
              "  Span(start=0, end=13)],\n",
              " 'target_id': ['81207500663427072::0',\n",
              "  '81207500663427072::1',\n",
              "  '81207500663427072::2'],\n",
              " 'target_sentiments': ['neutral', 'positive', 'neutral'],\n",
              " 'targets': ['Police', 'crime', 'Conservatives'],\n",
              " 'text': 'Conservatives cut the Police budget and this cut crime! Maybe not... #spin #BattleForNumber10',\n",
              " 'text_id': '81207500663427072'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NiaXfavBUsyO",
        "colab_type": "text"
      },
      "source": [
        "Lets say that we now want to add the predictions from `model_1` in `dataset_1` to `dataset_2` we can do this as follows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PN7cqF4CTLLM",
        "colab_type": "code",
        "outputId": "cc3698a5-28f5-4657-8240-5fbb6e90d314",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        }
      },
      "source": [
        "dataset_2.combine_data_on_id(dataset_1, 'target_id', ['model_1_predictions'])\n",
        "next(dataset_2.dict_iterator())"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'categories': None,\n",
              " 'category_sentiments': None,\n",
              " 'model_1_predictions': ['positive', 'positive', 'negative'],\n",
              " 'model_2_predictions': ['negative', 'negative', 'positive'],\n",
              " 'spans': [Span(start=22, end=28),\n",
              "  Span(start=49, end=54),\n",
              "  Span(start=0, end=13)],\n",
              " 'target_id': ['81207500663427072::0',\n",
              "  '81207500663427072::1',\n",
              "  '81207500663427072::2'],\n",
              " 'target_sentiments': ['neutral', 'positive', 'neutral'],\n",
              " 'targets': ['Police', 'crime', 'Conservatives'],\n",
              " 'text': 'Conservatives cut the Police budget and this cut crime! Maybe not... #spin #BattleForNumber10',\n",
              " 'text_id': '81207500663427072'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4rekzsWqWIdo",
        "colab_type": "text"
      },
      "source": [
        "As we can see above `dataset_2` now has the predictions from `model_1` from `dataset_1` and predicitons are aligned correctly according to the `target_id` key.\n",
        "\n",
        "The `combine_data_on_id` function mainly takes 3 arguments:\n",
        "1. The dataset/`TargetTextCollection` that contains the data. In our case `dataset_1`\n",
        "2. The key that both dataset can align with `target_id`\n",
        "3. The name of the key's that contain the data from the dataset (`dataset_1`) that you want in our case `model_1_predictions`\n",
        "\n",
        "Sometimes the number of keys of data you want from another dataset is quite large in that case you can use the following function to find the key difference between two datasets:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0Ejg-LMVBof",
        "colab_type": "code",
        "outputId": "a6088358-c3fe-410f-b42e-4e2748f7f4bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dataset_1.key_difference(dataset_2)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['model_2_predictions']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HvtfbnepXH7F",
        "colab_type": "code",
        "outputId": "341b00f4-8a2d-4efe-e645-565f5ce011d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dataset_2.key_difference(dataset_1)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5EgD7eBlXMOA",
        "colab_type": "text"
      },
      "source": [
        "The reason why there is no key difference between `dataset_2` and `dataset_1` is because we have just added that key data to `dataset_2`.\n",
        "\n",
        "If you ran the `combine_data_on_id` function again you will get the following error:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jpL1YzKXKHm",
        "colab_type": "code",
        "outputId": "6e6ed236-d6c1-421a-ab83-ac72dbc480e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        }
      },
      "source": [
        "dataset_2.combine_data_on_id(dataset_1, 'target_id', ['model_1_predictions'])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OverwriteError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOverwriteError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-0c0fb2f465be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdataset_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcombine_data_on_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'target_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'model_1_predictions'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/target_extraction/data_types.py\u001b[0m in \u001b[0;36mcombine_data_on_id\u001b[0;34m(self, other_collection, id_key, data_keys, raise_on_overwrite, check_same_ids)\u001b[0m\n\u001b[1;32m   2319\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2320\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself_copy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2321\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2323\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/target_extraction/data_types.py\u001b[0m in \u001b[0;36mcombine_data_on_id\u001b[0;34m(self, other_collection, id_key, data_keys, raise_on_overwrite, check_same_ids)\u001b[0m\n\u001b[1;32m   2290\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mdata_key\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_keys\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2291\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mdata_key\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself_target_text\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mraise_on_overwrite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2292\u001b[0;31m                         raise OverwriteError(f'The following data key {data_key}'\n\u001b[0m\u001b[1;32m   2293\u001b[0m                                              \u001b[0;34m' exists in the following TargetText'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2294\u001b[0m                                              \u001b[0;34mf' {self_target_text} within this collection. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOverwriteError\u001b[0m: The following data key model_1_predictions exists in the following TargetText TargetText({'text': 'Conservatives cut the Police budget and this cut crime! Maybe not... #spin #BattleForNumber10', 'text_id': '81207500663427072', 'targets': ['Police', 'crime', 'Conservatives'], 'spans': [Span(start=22, end=28), Span(start=49, end=54), Span(start=0, end=13)], 'target_sentiments': ['neutral', 'positive', 'neutral'], 'categories': None, 'category_sentiments': None, 'target_id': ['81207500663427072::0', '81207500663427072::1', '81207500663427072::2'], 'model_2_predictions': ['negative', 'negative', 'positive'], 'model_1_predictions': ['positive', 'positive', 'negative']}) within this collection. The other TargetText that contains this data key to copy the data from is TargetText({'text': 'Conservatives cut the Police budget and this cut crime! Maybe not... #spin #BattleForNumber10', 'text_id': '81207500663427072', 'targets': ['Conservatives', 'Police', 'crime'], 'spans': [Span(start=0, end=13), Span(start=22, end=28), Span(start=49, end=54)], 'target_sentiments': ['neutral', 'neutral', 'positive'], 'categories': None, 'category_sentiments': None, 'target_id': ['81207500663427072::2', '81207500663427072::0', '81207500663427072::1'], 'model_1_predictions': ['negative', 'positive', 'positive']})"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "luKXKYUmXf_c",
        "colab_type": "text"
      },
      "source": [
        "This is because by default it will raise an error if you try to overwrite any data this can behaviour can be changed like so:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hq0xoR3LXfTC",
        "colab_type": "code",
        "outputId": "0aa795c9-61f9-4e04-bd1d-da7fcb33ccc0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        }
      },
      "source": [
        "dataset_2.combine_data_on_id(dataset_1, 'target_id', ['model_1_predictions'], \n",
        "                             raise_on_overwrite=False)\n",
        "next(dataset_2.dict_iterator())"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'categories': None,\n",
              " 'category_sentiments': None,\n",
              " 'model_1_predictions': ['positive', 'positive', 'negative'],\n",
              " 'model_2_predictions': ['negative', 'negative', 'positive'],\n",
              " 'spans': [Span(start=22, end=28),\n",
              "  Span(start=49, end=54),\n",
              "  Span(start=0, end=13)],\n",
              " 'target_id': ['81207500663427072::0',\n",
              "  '81207500663427072::1',\n",
              "  '81207500663427072::2'],\n",
              " 'target_sentiments': ['neutral', 'positive', 'neutral'],\n",
              " 'targets': ['Police', 'crime', 'Conservatives'],\n",
              " 'text': 'Conservatives cut the Police budget and this cut crime! Maybe not... #spin #BattleForNumber10',\n",
              " 'text_id': '81207500663427072'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s0h8N62jXtxW",
        "colab_type": "text"
      },
      "source": [
        "As you can see no error and no change in data as we only combined the data that already existed.\n",
        "\n",
        "### In-Detail Combining data\n",
        "In this small sub-section we want to describe how `combine_data_on_id` works when your predictions are not just single predicitons but multiple predictions per target as you have run the same model multiple times to take into account the [random seed problem](https://www.aclweb.org/anthology/D17-1035.pdf) for example.\n",
        "\n",
        "In the setup below we have a similar setup as before; `dataset_3` contains `model_1` and `dataset_4` contains `model_2`, and `dataset_3` is re-ordered. `model_1` predicts all positive unless the target is `Conservatives` and the vice versa for `model_2`. However un-like before we now run each model 8 times for example as each run takes into account a different random seed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cm4dbhIeMJRA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "outputId": "12cc7567-873b-4960-ea0b-907cdb9a4ac2"
      },
      "source": [
        "dataset_3 = wang_2017_election_twitter_train()\n",
        "dataset_4 = wang_2017_election_twitter_train()\n",
        "# Add the unique target ids\n",
        "for dataset in [dataset_3, dataset_4]:\n",
        "  dataset.add_unique_key('targets', 'target_id')\n",
        "# re-order dataset_1\n",
        "dataset_3.re_order()\n",
        "# add predictions to datasets\n",
        "add_fictional_predictions(dataset_3, 'model_1', True, number_runs=8)\n",
        "add_fictional_predictions(dataset_4, 'model_2', False, number_runs=8)\n",
        "\n",
        "next(dataset_3.dict_iterator())"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'categories': None,\n",
              " 'category_sentiments': None,\n",
              " 'model_1_predictions': [['negative', 'positive', 'positive'],\n",
              "  ['negative', 'positive', 'positive'],\n",
              "  ['negative', 'positive', 'positive'],\n",
              "  ['negative', 'positive', 'positive'],\n",
              "  ['negative', 'positive', 'positive'],\n",
              "  ['negative', 'positive', 'positive'],\n",
              "  ['negative', 'positive', 'positive'],\n",
              "  ['negative', 'positive', 'positive']],\n",
              " 'spans': [Span(start=0, end=13),\n",
              "  Span(start=22, end=28),\n",
              "  Span(start=49, end=54)],\n",
              " 'target_id': ['81207500663427072::2',\n",
              "  '81207500663427072::0',\n",
              "  '81207500663427072::1'],\n",
              " 'target_sentiments': ['neutral', 'neutral', 'positive'],\n",
              " 'targets': ['Conservatives', 'Police', 'crime'],\n",
              " 'text': 'Conservatives cut the Police budget and this cut crime! Maybe not... #spin #BattleForNumber10',\n",
              " 'text_id': '81207500663427072'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QG23q0KJMdm9",
        "colab_type": "text"
      },
      "source": [
        "A sample from `dataset_3` is above and `dataset_4` below. From these samples we can now see that the predictions are a `List[List]` list of a list where the inner list relates to the `targets` and the outer list relates to the number of model runs (8)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2Ux0_SAMaSM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "outputId": "557baf8a-cd36-4e16-a758-41b469c975d0"
      },
      "source": [
        "next(dataset_4.dict_iterator())"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'categories': None,\n",
              " 'category_sentiments': None,\n",
              " 'model_2_predictions': [['negative', 'negative', 'positive'],\n",
              "  ['negative', 'negative', 'positive'],\n",
              "  ['negative', 'negative', 'positive'],\n",
              "  ['negative', 'negative', 'positive'],\n",
              "  ['negative', 'negative', 'positive'],\n",
              "  ['negative', 'negative', 'positive'],\n",
              "  ['negative', 'negative', 'positive'],\n",
              "  ['negative', 'negative', 'positive']],\n",
              " 'spans': [Span(start=22, end=28),\n",
              "  Span(start=49, end=54),\n",
              "  Span(start=0, end=13)],\n",
              " 'target_id': ['81207500663427072::0',\n",
              "  '81207500663427072::1',\n",
              "  '81207500663427072::2'],\n",
              " 'target_sentiments': ['neutral', 'positive', 'neutral'],\n",
              " 'targets': ['Police', 'crime', 'Conservatives'],\n",
              " 'text': 'Conservatives cut the Police budget and this cut crime! Maybe not... #spin #BattleForNumber10',\n",
              " 'text_id': '81207500663427072'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dxFQ3grLMstC",
        "colab_type": "text"
      },
      "source": [
        "Now that we have these datasets we want the predictions from `model_2` combined into `dataset_3` which can be done like before using `combine_data_on_id`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKT9-MPIMdFV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset_3.combine_data_on_id(dataset_4, 'target_id', data_keys=['model_2_predictions'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7AMbQeuNGI9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "outputId": "2c73bf9d-0597-479a-8f2e-bfe44f7f3f09"
      },
      "source": [
        "next(dataset_3.dict_iterator())"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'categories': None,\n",
              " 'category_sentiments': None,\n",
              " 'model_1_predictions': [['negative', 'positive', 'positive'],\n",
              "  ['negative', 'positive', 'positive'],\n",
              "  ['negative', 'positive', 'positive'],\n",
              "  ['negative', 'positive', 'positive'],\n",
              "  ['negative', 'positive', 'positive'],\n",
              "  ['negative', 'positive', 'positive'],\n",
              "  ['negative', 'positive', 'positive'],\n",
              "  ['negative', 'positive', 'positive']],\n",
              " 'model_2_predictions': [['positive', 'negative', 'negative'],\n",
              "  ['positive', 'negative', 'negative'],\n",
              "  ['positive', 'negative', 'negative'],\n",
              "  ['positive', 'negative', 'negative'],\n",
              "  ['positive', 'negative', 'negative'],\n",
              "  ['positive', 'negative', 'negative'],\n",
              "  ['positive', 'negative', 'negative'],\n",
              "  ['positive', 'negative', 'negative']],\n",
              " 'spans': [Span(start=0, end=13),\n",
              "  Span(start=22, end=28),\n",
              "  Span(start=49, end=54)],\n",
              " 'target_id': ['81207500663427072::2',\n",
              "  '81207500663427072::0',\n",
              "  '81207500663427072::1'],\n",
              " 'target_sentiments': ['neutral', 'neutral', 'positive'],\n",
              " 'targets': ['Conservatives', 'Police', 'crime'],\n",
              " 'text': 'Conservatives cut the Police budget and this cut crime! Maybe not... #spin #BattleForNumber10',\n",
              " 'text_id': '81207500663427072'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NaZOVDoeNJyj",
        "colab_type": "text"
      },
      "source": [
        "As we can see above the `model_2_predictions` are now in `dataset_3`."
      ]
    }
  ]
}