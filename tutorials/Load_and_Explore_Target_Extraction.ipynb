{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Load and Explore Target Extraction.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/apmoore1/target-extraction/blob/master/tutorials/Load_and_Explore_Target_Extraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1jKAOJcq40t",
        "colab_type": "code",
        "outputId": "5f90f5aa-a0fa-449b-a6f4-f2acb0bfe8b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 703
        }
      },
      "source": [
        "#%%capture\n",
        "!pip uninstall target-extraction\n",
        "!pip install git+git://github.com/apmoore1/target-extraction.git@master#egg=target-extraction"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling target-extraction-0.0.1:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.6/dist-packages/target_extraction-0.0.1.dist-info/*\n",
            "    /usr/local/lib/python3.6/dist-packages/target_extraction/*\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled target-extraction-0.0.1\n",
            "Collecting target-extraction from git+git://github.com/apmoore1/target-extraction.git@master#egg=target-extraction\n",
            "  Cloning git://github.com/apmoore1/target-extraction.git (to revision master) to /tmp/pip-install-c98jy2pi/target-extraction\n",
            "  Running command git clone -q git://github.com/apmoore1/target-extraction.git /tmp/pip-install-c98jy2pi/target-extraction\n",
            "Requirement already satisfied: spacy==2.1.4 in /usr/local/lib/python3.6/dist-packages (from target-extraction) (2.1.4)\n",
            "Requirement already satisfied: torch==1.0.0 in /usr/local/lib/python3.6/dist-packages (from target-extraction) (1.0.0)\n",
            "Requirement already satisfied: stanfordnlp==0.2.0 in /usr/local/lib/python3.6/dist-packages (from target-extraction) (0.2.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from spacy==2.1.4->target-extraction) (0.0.5)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy==2.1.4->target-extraction) (1.16.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy==2.1.4->target-extraction) (2.21.0)\n",
            "Requirement already satisfied: blis<0.3.0,>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from spacy==2.1.4->target-extraction) (0.2.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy==2.1.4->target-extraction) (1.0.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy==2.1.4->target-extraction) (2.0.2)\n",
            "Requirement already satisfied: plac<1.0.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy==2.1.4->target-extraction) (0.9.6)\n",
            "Requirement already satisfied: jsonschema<3.1.0,>=2.6.0 in /usr/local/lib/python3.6/dist-packages (from spacy==2.1.4->target-extraction) (2.6.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from spacy==2.1.4->target-extraction) (0.2.2)\n",
            "Requirement already satisfied: thinc<7.1.0,>=7.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy==2.1.4->target-extraction) (7.0.4)\n",
            "Requirement already satisfied: preshed<2.1.0,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from spacy==2.1.4->target-extraction) (2.0.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from stanfordnlp==0.2.0->target-extraction) (4.28.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from stanfordnlp==0.2.0->target-extraction) (3.7.1)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.1.4->target-extraction) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.1.4->target-extraction) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.1.4->target-extraction) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.1.4->target-extraction) (2019.3.9)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->stanfordnlp==0.2.0->target-extraction) (41.0.1)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.6/dist-packages (from protobuf->stanfordnlp==0.2.0->target-extraction) (1.12.0)\n",
            "Building wheels for collected packages: target-extraction\n",
            "  Building wheel for target-extraction (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-4hv_epdc/wheels/49/38/dd/3a8462a96b96857513b9f7f42036f80db8e77a32291f62e80e\n",
            "Successfully built target-extraction\n",
            "Installing collected packages: target-extraction\n",
            "Successfully installed target-extraction-0.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rC3dzvwArEDd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from target_extraction.dataset_parsers import semeval_2014, semeval_2016"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_UIzh7HtrMTW",
        "colab_type": "text"
      },
      "source": [
        "# Loads and explore datasets\n",
        "In this notebook we will show you how to load two of the popular SemEval datasets into the TargetTextCollection object format. Next we will show you the advantage of this easy to use format through serveral built in functions such as:\n",
        "\n",
        "1. Dataset Statistics -- counts of sentences and targets.\n",
        "2. Built in tokenization and POS tagging.\n",
        "3. Import and export to JSON format which is useful if you want to use the data in an [AllenNLP model](https://allennlp.org/)\n",
        "4. Setting the task of Target Extraction into a Sequence Labelling task\n",
        "\n",
        "## Loading datasets\n",
        "First we are going to show you how to load the following popular datasets:\n",
        "1. [SemEval 2014 task 4 Laptop domain (laptop)](http://alt.qcri.org/semeval2014/task4/). Of which the training data can be found [here](http://metashare.ilsp.gr:8080/repository/browse/semeval-2014-absa-train-data-v20-annotation-guidelines/683b709298b811e3a0e2842b2b6a04d7c7a19307f18a4940beef6a6143f937f0/) and the test data [here](http://metashare.ilsp.gr:8080/repository/browse/semeval-2014-absa-test-data-gold-annotations/b98d11cec18211e38229842b2b6a04d77591d40acd7542b7af823a54fb03a155/).\n",
        "2. [SemEval 2014 task 4 Restaurant domain (restaurant_14)](http://alt.qcri.org/semeval2014/task4/). Of which the training and the test data can be found at the same place as the laptop dataset.\n",
        "3. [SemEval 2016 task 5 Restaurant domain (restaurant_16)](http://alt.qcri.org/semeval2016/task5/). Of which the training data can be found [here](http://metashare.ilsp.gr:8080/repository/browse/semeval-2016-absa-restaurant-reviews-english-train-data-subtask-1/cd28e738562f11e59e2c842b2b6a04d703f9dae461bb4816a5d4320019407d23/) and the test data [here](http://metashare.ilsp.gr:8080/repository/browse/semeval-2016-absa-restaurant-reviews-english-test-data-gold-subtask-1/42bd97c6d17511e59dbe842b2b6a04d721d1933085814d9daed8fbcbe54c0615/).\n",
        "\n",
        "Assuming you have downloaded these files we will now upload them to this notebook, this will require 6 upload requests which will happen when you run the next cell; 1. The training, 2. test data for the laptop domain, 3. the training data, 4. test data for the restaurant_14, 5. the training data, and 6. test data for the restaurant_16"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8ENkPsdBQv0",
        "colab_type": "code",
        "outputId": "d50b0c36-7033-4937-b0a5-d88251c2b092",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "source": [
        "from pathlib import Path\n",
        "from google.colab import files\n",
        "uploaded = {}\n",
        "for i in range(6):\n",
        "  temp_uploaded = files.upload()\n",
        "  uploaded = {**uploaded, **temp_uploaded}\n",
        "semeval_fps = [Path(key).resolve() for key in uploaded.keys()]\n",
        "semeval_fps = {semeval_path.name: semeval_path for semeval_path in semeval_fps}\n",
        "del uploaded\n",
        "# Paths to the files uploaded\n",
        "for file_name, fp in semeval_fps.items():\n",
        "  print(f'SemEval file name: {file_name}. File Path {fp}')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-51b995e6-9d19-4b79-919c-69ec9883ff7a\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-51b995e6-9d19-4b79-919c-69ec9883ff7a\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving Laptop_Train_v2.xml to Laptop_Train_v2 (2).xml\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-b51cf346-0bb6-4ef5-acef-9b2060a269c7\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-b51cf346-0bb6-4ef5-acef-9b2060a269c7\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving Restaurants_Train_v2.xml to Restaurants_Train_v2 (2).xml\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-6868af2f-83ca-4e07-8717-b5c1240bbf35\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-6868af2f-83ca-4e07-8717-b5c1240bbf35\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving Laptops_Test_Gold.xml to Laptops_Test_Gold (2).xml\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-6a8749f0-08d9-4f17-a1eb-5753438ab71e\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-6a8749f0-08d9-4f17-a1eb-5753438ab71e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving Restaurants_Test_Gold.xml to Restaurants_Test_Gold (2).xml\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-51dc21c6-d2cb-42cd-a270-c8f7fd176d1c\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-51dc21c6-d2cb-42cd-a270-c8f7fd176d1c\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving EN_REST_SB1_TEST.xml.gold to EN_REST_SB1_TEST.xml (2).gold\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-b2c0a8fb-52c5-4cc6-b06f-18b062e37a2c\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-b2c0a8fb-52c5-4cc6-b06f-18b062e37a2c\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving ABSA16_Restaurants_Train_SB1_v2.xml to ABSA16_Restaurants_Train_SB1_v2 (2).xml\n",
            "SemEval file name: Laptop_Train_v2.xml. File Path /content/Laptop_Train_v2.xml\n",
            "SemEval file name: Restaurants_Train_v2.xml. File Path /content/Restaurants_Train_v2.xml\n",
            "SemEval file name: Laptops_Test_Gold.xml. File Path /content/Laptops_Test_Gold.xml\n",
            "SemEval file name: Restaurants_Test_Gold.xml. File Path /content/Restaurants_Test_Gold.xml\n",
            "SemEval file name: EN_REST_SB1_TEST.xml.gold. File Path /content/EN_REST_SB1_TEST.xml.gold\n",
            "SemEval file name: ABSA16_Restaurants_Train_SB1_v2.xml. File Path /content/ABSA16_Restaurants_Train_SB1_v2.xml\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFkzDLebEYEQ",
        "colab_type": "text"
      },
      "source": [
        "We will now load the data into TargetTextCollection format:\n",
        "\n",
        "NOTE: The `conflict` argument states whether or not to include targets or categories that contain the `conflict` sentiment. In this case we **do** want the `conflict` sentiment targets or categories thus the value is `False`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_n6UuGEDCPiX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "laptop_train = semeval_2014(semeval_fps['Laptop_Train_v2.xml'], conflict=False)\n",
        "laptop_test = semeval_2014(semeval_fps['Laptops_Test_Gold.xml'], conflict=False)\n",
        "rest_14_train = semeval_2014(semeval_fps['Restaurants_Train_v2.xml'], conflict=False)\n",
        "rest_14_test = semeval_2014(semeval_fps['Restaurants_Test_Gold.xml'], conflict=False)\n",
        "rest_16_train = semeval_2016(semeval_fps['ABSA16_Restaurants_Train_SB1_v2.xml'], conflict=False)\n",
        "rest_16_test = semeval_2016(semeval_fps['EN_REST_SB1_TEST.xml.gold'], conflict=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bw6k6CP3k7h6",
        "colab_type": "text"
      },
      "source": [
        "## Dataset Statistics\n",
        "\n",
        "Now that we have loaded these datasets we can perform some dataset statistics on them, such as the number of sentences, number of sentences that contain at least one target in it, and the number of  targets in the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKe2wOa39dxA",
        "colab_type": "code",
        "outputId": "6814b124-9d61-4482-8c86-8957f5bd0558",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "from collections import defaultdict\n",
        "import pandas as pd\n",
        "\n",
        "name_dataset = [('Laptop Train', laptop_train), ('Laptop Test', laptop_test),\n",
        "                ('Restaurant 14 Train', rest_14_train), \n",
        "                ('Restaurant 14_Test', rest_14_test),\n",
        "                ('Restaurant 16 Train', rest_16_train), \n",
        "                ('Restaurant 16_Test', rest_16_test)]\n",
        "dataset_stats = defaultdict(lambda: {})\n",
        "\n",
        "for name, dataset in name_dataset:\n",
        "  num_sentences = len(dataset)\n",
        "  num_targ_sents = len(dataset.samples_with_targets())\n",
        "  num_targs = sum([count for count in dataset.target_count().values()])\n",
        "  \n",
        "  dataset_stats[name]['Number Sentences'] = num_sentences\n",
        "  dataset_stats[name]['Number Target Sentences'] = num_targ_sents\n",
        "  dataset_stats[name]['Number Targets'] = num_targs\n",
        "pd.DataFrame(dataset_stats).T  "
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Number Sentences</th>\n",
              "      <th>Number Target Sentences</th>\n",
              "      <th>Number Targets</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Laptop Train</th>\n",
              "      <td>3045</td>\n",
              "      <td>1488</td>\n",
              "      <td>2358</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Laptop Test</th>\n",
              "      <td>800</td>\n",
              "      <td>422</td>\n",
              "      <td>654</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Restaurant 14 Train</th>\n",
              "      <td>3041</td>\n",
              "      <td>2021</td>\n",
              "      <td>3693</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Restaurant 14_Test</th>\n",
              "      <td>800</td>\n",
              "      <td>606</td>\n",
              "      <td>1134</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Restaurant 16 Train</th>\n",
              "      <td>2000</td>\n",
              "      <td>1708</td>\n",
              "      <td>2507</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Restaurant 16_Test</th>\n",
              "      <td>676</td>\n",
              "      <td>587</td>\n",
              "      <td>859</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     Number Sentences  Number Target Sentences  Number Targets\n",
              "Laptop Train                     3045                     1488            2358\n",
              "Laptop Test                       800                      422             654\n",
              "Restaurant 14 Train              3041                     2021            3693\n",
              "Restaurant 14_Test                800                      606            1134\n",
              "Restaurant 16 Train              2000                     1708            2507\n",
              "Restaurant 16_Test                676                      587             859"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w8npYR_a5utG",
        "colab_type": "text"
      },
      "source": [
        "These statistics match those of the original SemEval task 4 subtask 1 2014 Laptop/Restaurant dataset [paper](https://www.aclweb.org/anthology/S14-2004), and original SemEval task 5 subtask 1 2016 Restaurant dataset [paper](https://www.aclweb.org/anthology/S16-1002).\n",
        "\n",
        "However the Restaurant 2016 dataset is reporting the number of (targets, categories) which means that for the target extraction task this is not ideal as we can have duplicate targets with the same spans in the same sentence as each one of those duplicate targets can have a different category. An example of this is shown below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDJNhXNl47Xw",
        "colab_type": "code",
        "outputId": "ced2eef2-2f3e-486c-be4f-314be249aff5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "sample = rest_16_train['1086415:2']\n",
        "sample"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TargetText({'text': '$6 and there is much tasty food, all of it fresh and continually refilled.', 'text_id': '1086415:2', 'targets': ['food', 'food', 'food'], 'spans': [Span(start=27, end=31), Span(start=27, end=31), Span(start=27, end=31)], 'target_sentiments': ['positive', 'positive', 'positive'], 'categories': ['FOOD#STYLE_OPTIONS', 'FOOD#QUALITY', 'FOOD#PRICES'], 'category_sentiments': None})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVXx77-N7WCR",
        "colab_type": "text"
      },
      "source": [
        "As we can see in the example above the target food with the eaxct same span is used three times as each time it has a different category associated to it. To convert the dataset into one that only allows one target with one span use the `one_sample_per_span` function to create a new TargetTextCollection dataset (NOTE: This is only required for the Restaurant 2016 dataset as the previous datasets did not link the target and categories together):\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ut_BRAFvUYeX",
        "colab_type": "code",
        "outputId": "8c5f2f84-c22e-4c91-fefc-0bfdde837e06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "rest_target_16_train = rest_16_train.one_sample_per_span(remove_empty=True)\n",
        "rest_target_16_test = rest_16_test.one_sample_per_span(remove_empty=True)\n",
        "\n",
        "sample = rest_target_16_train['1086415:2']\n",
        "sample"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TargetText({'text': '$6 and there is much tasty food, all of it fresh and continually refilled.', 'text_id': '1086415:2', 'targets': ['food'], 'spans': [Span(start=27, end=31)], 'target_sentiments': None, 'categories': None, 'category_sentiments': None})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0A8cFUUUYmn",
        "colab_type": "text"
      },
      "source": [
        "As we can see above the TargetText instance now only has `food` once but we have had to remove all of the category information and sentiment. However this is perfect if we want to just perform the Target Extraction task. \n",
        "\n",
        "NOTE: The `remove_empty=True` argument is required as some of the (target, category) pairs contain targets that are None as in the target does not exist but the category does therefore setting this argument to `True` removes these None targets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wc8hpoCzAE_c",
        "colab_type": "code",
        "outputId": "bc644ed3-40ff-4247-dc9b-d06cdde002ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "name_dataset = [('Laptop Train', laptop_train), ('Laptop Test', laptop_test),\n",
        "                ('Restaurant 14 Train', rest_14_train), \n",
        "                ('Restaurant 14_Test', rest_14_test),\n",
        "                ('Restaurant 16 Train', rest_target_16_train), \n",
        "                ('Restaurant 16_Test', rest_target_16_test)]\n",
        "dataset_stats = defaultdict(lambda: {})\n",
        "\n",
        "for name, dataset in name_dataset:\n",
        "  num_sentences = len(dataset)\n",
        "  num_targ_sents = len(dataset.samples_with_targets())\n",
        "  num_targs = sum([count for count in dataset.samples_with_targets().target_count().values()])\n",
        "  \n",
        "  dataset_stats[name]['Number Sentences'] = num_sentences\n",
        "  dataset_stats[name]['Number Target Sentences'] = num_targ_sents\n",
        "  dataset_stats[name]['Number Targets'] = num_targs\n",
        "pd.DataFrame(dataset_stats).T  "
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Number Sentences</th>\n",
              "      <th>Number Target Sentences</th>\n",
              "      <th>Number Targets</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Laptop Train</th>\n",
              "      <td>3045</td>\n",
              "      <td>1488</td>\n",
              "      <td>2358</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Laptop Test</th>\n",
              "      <td>800</td>\n",
              "      <td>422</td>\n",
              "      <td>654</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Restaurant 14 Train</th>\n",
              "      <td>3041</td>\n",
              "      <td>2021</td>\n",
              "      <td>3693</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Restaurant 14_Test</th>\n",
              "      <td>800</td>\n",
              "      <td>606</td>\n",
              "      <td>1134</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Restaurant 16 Train</th>\n",
              "      <td>2000</td>\n",
              "      <td>1235</td>\n",
              "      <td>1745</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Restaurant 16_Test</th>\n",
              "      <td>676</td>\n",
              "      <td>421</td>\n",
              "      <td>613</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     Number Sentences  Number Target Sentences  Number Targets\n",
              "Laptop Train                     3045                     1488            2358\n",
              "Laptop Test                       800                      422             654\n",
              "Restaurant 14 Train              3041                     2021            3693\n",
              "Restaurant 14_Test                800                      606            1134\n",
              "Restaurant 16 Train              2000                     1235            1745\n",
              "Restaurant 16_Test                676                      421             613"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UIRfq7ep-2b8",
        "colab_type": "text"
      },
      "source": [
        "Now that we have re-run the statistics of the dataset we can see that the Restaurant dataset has changed with regards to the Number of targets and target sentences. These statistics are now more in line with previous work ([link](https://www.aclweb.org/anthology/D17-1310) [link](https://www.aclweb.org/anthology/N19-1242)). However there are some reasons why they are not identical only for the Restaurant 2016 dataset, these are artifacts in the original annotation that we found which we share below:\n",
        "\n",
        "### First annotation mistake\n",
        "This is the case where the annotation stats NULL for the target but give a Span value:\n",
        "\n",
        "``` xml\n",
        "<sentence id=\"en_SchoonerOrLater_477965850:10\">\n",
        "  <text>In short, Schooner or Later couldn't have cared less about our being at their establishment.</text>\n",
        "  <Opinions>\n",
        "    <Opinion target=\"NULL\" category=\"SERVICE#GENERAL\" polarity=\"negative\" from=\"10\" to=\"27\"/>\n",
        "  </Opinions>\n",
        "</sentence>\n",
        "```\n",
        "In these cases we change target from `NULL` to `Schooner or Later` and more generally to the text that the span refers to.\n",
        "\n",
        "These mistakes add more targets to the dataset of which in the Restaurant train and test dataset there were 3 (1 of which linked to an exisitng target as in that target now existed twice with difference categories) and 1 mistakes respectively.\n",
        "\n",
        "### Second annotation mistake\n",
        "Annotation stats NULL for the target but the Span value is given but makes no sense:\n",
        "\n",
        "``` xml\n",
        "<sentence id=\"en_MercedesRestaurant_478010600:1\">\n",
        "  <text>– !</text>\n",
        "  <Opinions>\n",
        "    <Opinion target=\"service\" category=\"SERVICE#GENERAL\" polarity=\"positive\" from=\"39\" to=\"46\"/>\n",
        "    <Opinion target=\"NULL\" category=\"FOOD#QUALITY\" polarity=\"positive\" from=\"2\" to=\"21\"/>\n",
        "  </Opinions>\n",
        "</sentence>\n",
        "```\n",
        "As we can see that there is a target which is `NULL` but the spans refers to the following text `rcedes restaurant i` which just makes no sense. Therefore in these cases we leave the target as it does not exist and change the spans to `from = 0` and `to = 0`. In these case they do not affect the overall statistics it just highlights mistakes that have been made. In the Restaurant train and test dataset there were 1 and 4 mistakes respectively.\n",
        "\n",
        "## Tokenization\n",
        "\n",
        "The `target_extraction` has a few tokenization options avaliable:\n",
        "1. [Spacy](https://spacy.io/) -- Rule based tokenizer. \n",
        "2. [Stanford](https://stanfordnlp.github.io/stanfordnlp/), related [paper](https://www.aclweb.org/anthology/K18-2016) -- Neural Network based tokenizer.\n",
        "3. Whitespace.\n",
        "\n",
        "Both the Spacy and Stanford tokenizers support multiple languages.\n",
        "\n",
        "To use any of the tokenizers we have to call the tokenizers method to get a related tokenizer as shown below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6uFrcF0F3WD",
        "colab_type": "code",
        "outputId": "ef01864d-b92c-411f-99ac-7d0ed8bb4bcf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        }
      },
      "source": [
        "from target_extraction import tokenizers\n",
        "\n",
        "example_sentence = \"I've had a great day today. The tokenizer's work well.\"\n",
        "\n",
        "# Get different spacy tokenizers\n",
        "# English is the default language\n",
        "spacy_tok_en = tokenizers.spacy_tokenizer()\n",
        "# German\n",
        "spacy_tok_de = tokenizers.spacy_tokenizer(lang='de')\n",
        "\n",
        "\n",
        "# Get different Stanford tokenizers\n",
        "# English again is the default language and the default treebank is EWT\n",
        "stanford_tok_en = tokenizers.stanford()\n",
        "# Dutch but with a treebank that is not default\n",
        "stanford_tok_nl = tokenizers.stanford(lang='nl', treebank='lassysmall')\n",
        "\n",
        "\n",
        "# Whitespace\n",
        "whitespace_tok = tokenizers.whitespace()\n",
        "\n",
        "print(f'Spacy: {spacy_tok_en(example_sentence)}')\n",
        "print(f'Stanford: {stanford_tok_en(example_sentence)}')\n",
        "print(f'Whitespace {whitespace_tok(example_sentence)}')\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Use device: cpu\n",
            "---\n",
            "Loading: tokenize\n",
            "With settings: \n",
            "{'model_path': '/root/stanfordnlp_resources/en_ewt_models/en_ewt_tokenizer.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
            "Done loading processors!\n",
            "---\n",
            "Use device: cpu\n",
            "---\n",
            "Loading: tokenize\n",
            "With settings: \n",
            "{'model_path': '/root/stanfordnlp_resources/nl_lassysmall_models/nl_lassysmall_tokenizer.pt', 'lang': 'nl', 'shorthand': 'nl_lassysmall', 'mode': 'predict'}\n",
            "Done loading processors!\n",
            "---\n",
            "Spacy: ['I', \"'ve\", 'had', 'a', 'great', 'day', 'today', '.', 'The', 'tokenizer', \"'s\", 'work', 'well', '.']\n",
            "Stanford: ['I', \"'ve\", 'had', 'a', 'great', 'day', 'today', '.', 'The', 'tokenizer', \"'s\", 'work', 'well', '.']\n",
            "Whitespace [\"I've\", 'had', 'a', 'great', 'day', 'today.', 'The', \"tokenizer's\", 'work', 'well.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "debbcG-QJAuN",
        "colab_type": "text"
      },
      "source": [
        "As we can see the Spacy and the Stanford tokenizers are more similar than the whitespacy with regards to handling full stops and hyphons.\n",
        "\n",
        "We can also use these tokenizers to tokenizse the whole of our datasets easily as shown below (in the example below we use the Stanford tokenizer):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Ch0NqWX0Q65",
        "colab_type": "code",
        "outputId": "f0a62f43-94d1-41ec-a868-ddadc5a9a4a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        }
      },
      "source": [
        "# Tokenize each dataset\n",
        "for name, dataset in name_dataset:\n",
        "  print(name)\n",
        "  dataset.tokenize(stanford_tok_en)\n",
        "\n",
        "sample = rest_target_16_train['1086415:2']\n",
        "print(f\"Text: {sample['text']}\\nTokens: {sample['tokenized_text']}\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Laptop Train\n",
            "Laptop Test\n",
            "Restaurant 14 Train\n",
            "Restaurant 14_Test\n",
            "Restaurant 16 Train\n",
            "Restaurant 16_Test\n",
            "Text: $6 and there is much tasty food, all of it fresh and continually refilled.\n",
            "Tokens: ['$', '6', 'and', 'there', 'is', 'much', 'tasty', 'food', ',', 'all', 'of', 'it', 'fresh', 'and', 'continually', 'refilled', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kYyrQDX4VAHd",
        "colab_type": "text"
      },
      "source": [
        "We sample within the TargetTextCollection now has a new property (key in the internal disctionary) `tokenized_text` which contains the tokenized text for that sample.\n",
        "\n",
        "## POS Tagging\n",
        "The `target_extraction` has a couple of POS tagging options avaliable:\n",
        "1. [Spacy](https://spacy.io/) -- Neural Network based. \n",
        "2. [Stanford](https://stanfordnlp.github.io/stanfordnlp/), related [paper](https://www.aclweb.org/anthology/K18-2016) -- Neural Network based.\n",
        "\n",
        "Both the Spacy and Stanford POS taggers support multiple languages. They also both support two different types of tag sets:\n",
        "1. [Universal POS tags (coarse)](https://universaldependencies.org/u/pos/) -- These are the same tags accross languages.\n",
        "2. Language Specific (fine) -- These are language independent tags and are usuall more fine grained than the Universal, an example of this tag set would be the [Penn Treebank](https://www.clips.uantwerpen.be/pages/mbsp-tags).\n",
        "\n",
        "To use any of the POS taggers we have to call the POS tagger's method to get the related POS tagger as shown below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fkzuuM8q8Sph",
        "colab_type": "code",
        "outputId": "2530f734-5b63-4381-8e35-c7e10c40bfcf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 685
        }
      },
      "source": [
        "from target_extraction import pos_taggers\n",
        "\n",
        "example_sentence = \"I've had a great day today. The tokenizer's work well.\"\n",
        "\n",
        "# Get different spacy tokenizers\n",
        "# English is the default language with the small model and here we have chosen \n",
        "# the universal tag set\n",
        "spacy_pos_en = pos_taggers.spacy_tagger(fine=False)\n",
        "# German with the small model and language independent tag set\n",
        "spacy_pos_de = pos_taggers.spacy_tagger(spacy_model_name='de_core_news_sm', \n",
        "                                        fine=True)\n",
        "\n",
        "\n",
        "# Get different Stanford tokenizers\n",
        "# English again is the default language and the default treebank is EWT, \n",
        "# using language independent tag set.\n",
        "stanford_pos_en_fine = pos_taggers.stanford(fine=True)\n",
        "# Dutch but with a treebank that is not default and language independent tag set\n",
        "stanford_pos_nl = pos_taggers.stanford(lang='nl', treebank='lassysmall', fine=True)\n",
        "# English again is the default language and the default treebank is EWT, \n",
        "# using the universal tag set\n",
        "stanford_pos_en_coarse = pos_taggers.stanford(fine=False)\n",
        "\n",
        "print(f'Stanford Language Independent: {stanford_pos_en_fine(example_sentence)}')\n",
        "print(f'Stanford Universal: {stanford_pos_en_coarse(example_sentence)}')\n",
        "print(f'Spacy: {spacy_pos_en(example_sentence)}')\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Use device: cpu\n",
            "---\n",
            "Loading: tokenize\n",
            "With settings: \n",
            "{'model_path': '/root/stanfordnlp_resources/en_ewt_models/en_ewt_tokenizer.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
            "---\n",
            "Loading: pos\n",
            "With settings: \n",
            "{'model_path': '/root/stanfordnlp_resources/en_ewt_models/en_ewt_tagger.pt', 'pretrain_path': '/root/stanfordnlp_resources/en_ewt_models/en_ewt.pretrain.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
            "Done loading processors!\n",
            "---\n",
            "Use device: cpu\n",
            "---\n",
            "Loading: tokenize\n",
            "With settings: \n",
            "{'model_path': '/root/stanfordnlp_resources/nl_lassysmall_models/nl_lassysmall_tokenizer.pt', 'lang': 'nl', 'shorthand': 'nl_lassysmall', 'mode': 'predict'}\n",
            "---\n",
            "Loading: pos\n",
            "With settings: \n",
            "{'model_path': '/root/stanfordnlp_resources/nl_lassysmall_models/nl_lassysmall_tagger.pt', 'pretrain_path': '/root/stanfordnlp_resources/nl_lassysmall_models/nl_lassysmall.pretrain.pt', 'lang': 'nl', 'shorthand': 'nl_lassysmall', 'mode': 'predict'}\n",
            "Done loading processors!\n",
            "---\n",
            "Use device: cpu\n",
            "---\n",
            "Loading: tokenize\n",
            "With settings: \n",
            "{'model_path': '/root/stanfordnlp_resources/en_ewt_models/en_ewt_tokenizer.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
            "---\n",
            "Loading: pos\n",
            "With settings: \n",
            "{'model_path': '/root/stanfordnlp_resources/en_ewt_models/en_ewt_tagger.pt', 'pretrain_path': '/root/stanfordnlp_resources/en_ewt_models/en_ewt.pretrain.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
            "Done loading processors!\n",
            "---\n",
            "Stanford Language Independent: ['PRP', 'VBP', 'VBN', 'DT', 'JJ', 'NN', 'NN', '.', 'DT', 'NN', 'POS', 'NN', 'RB', '.']\n",
            "Stanford Universal: ['PRON', 'AUX', 'VERB', 'DET', 'ADJ', 'NOUN', 'NOUN', 'PUNCT', 'DET', 'NOUN', 'PART', 'NOUN', 'ADV', 'PUNCT']\n",
            "Spacy: ['PRON', 'VERB', 'VERB', 'DET', 'ADJ', 'NOUN', 'NOUN', 'PUNCT', 'DET', 'NOUN', 'PART', 'NOUN', 'ADV', 'PUNCT']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3o_2NT8cZNLv",
        "colab_type": "text"
      },
      "source": [
        "We can easily see the difference between the universal and independent tag sets.\n",
        "\n",
        "Like the tokenizers we can easily POS tag the whole dataset as shown below: \n",
        "\n",
        "**NOTE** even the POS taggers do the whole pipeline of tokenization and POS tagging it does expect that the dataset has already been tokenized with the same tokenizer i.e. Stanford with the same language and treebank."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LEy1RJKG9BMs",
        "colab_type": "code",
        "outputId": "252f97b3-2be3-4b94-968c-24ad09c429ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        }
      },
      "source": [
        "# POS tag each dataset\n",
        "for name, dataset in name_dataset:\n",
        "  print(name)\n",
        "  dataset.pos_text(stanford_pos_en_coarse)\n",
        "\n",
        "sample = rest_target_16_train['1086415:2']\n",
        "print(f\"Text: {sample['text']}\\nTokens: {sample['tokenized_text']}\\nPOS tags: {sample['pos_tags']}\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Laptop Train\n",
            "Laptop Test\n",
            "Restaurant 14 Train\n",
            "Restaurant 14_Test\n",
            "Restaurant 16 Train\n",
            "Restaurant 16_Test\n",
            "Text: $6 and there is much tasty food, all of it fresh and continually refilled.\n",
            "Tokens: ['$', '6', 'and', 'there', 'is', 'much', 'tasty', 'food', ',', 'all', 'of', 'it', 'fresh', 'and', 'continually', 'refilled', '.']\n",
            "POS tags: ['SYM', 'NUM', 'CCONJ', 'PRON', 'VERB', 'ADV', 'ADJ', 'NOUN', 'PUNCT', 'DET', 'ADP', 'PRON', 'ADJ', 'CCONJ', 'ADV', 'VERB', 'PUNCT']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LizqSLg_dBqt",
        "colab_type": "text"
      },
      "source": [
        "## To and From JSON\n",
        "\n",
        "Once loaded into the TargetTextCollection format it is easy to export to JSON format and import into a TargetTextCollection from JSON as shown below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KzS0-jAsAPbO",
        "colab_type": "code",
        "outputId": "b6528f10-7d0a-47f8-cd71-97ca3ea3597f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "source": [
        "from target_extraction.data_types import TargetTextCollection\n",
        "\n",
        "example_json = laptop_train.to_json()[:200]\n",
        "print(f'Sample of the JSON: {example_json}')\n",
        "empty_collection = TargetTextCollection.from_json(laptop_train.to_json())\n",
        "empty_collection == laptop_train"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sample of the JSON: {\"text\": \"I charge it at night and skip taking the cord with me because of the good battery life.\", \"text_id\": \"2339\", \"targets\": [\"cord\", \"battery life\"], \"spans\": [[41, 45], [74, 86]], \"target_senti\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0n2imrvC1-l",
        "colab_type": "text"
      },
      "source": [
        "As we can see above we can export to a JSON string and import from a JSON string. Below we show similar methods but instead of exporting and importing from Strings we do this from Files or more specifically File Paths:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aEKt2heGC1ZN",
        "colab_type": "code",
        "outputId": "2a728ad5-77bf-44a7-fb38-66ebfb1d7ab7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from pathlib import Path\n",
        "import tempfile\n",
        "\n",
        "with tempfile.NamedTemporaryFile(mode='w+') as temp_file:\n",
        "  temp_fp = Path(temp_file.name)\n",
        "  laptop_train.to_json_file(temp_fp)\n",
        "  empty_collection = None\n",
        "  empty_collection = TargetTextCollection.load_json(temp_fp)\n",
        "  print(empty_collection == laptop_train)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-aKxDgWzD3Fd",
        "colab_type": "text"
      },
      "source": [
        "And as expected the TargetTextCollection loaded from the JSON file is the same as the one that exported it into JSON.\n",
        "\n",
        "## Creating the sequence labelling task for Target Extraction and the True Upper limit\n",
        "The Target Extraction (TE) task within Aspect Based Sentiment Analysis (ABSA) is normally formulated as a Sequence Labelling task ([paper link](https://www.aclweb.org/anthology/P18-2094)), however unlike other sequence labelling problems that have pre-tokenized text with gold sequence labels like [NER](https://www.aclweb.org/anthology/P16-1101) TE is evaluated based on Eaxct Span Matching not Sequence Labels.\n",
        "\n",
        "This means that if we do treat the task as a sequence labelling task we can have tokenization errors and we show this below and thus show (we believe) for the first time the true upper limit of TE when treating it as a sequence labelling task due to tokenization error."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTNzCGjaCgIt",
        "colab_type": "code",
        "outputId": "a83bbb40-ac3c-40cb-98e6-d34e1aa8a407",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        }
      },
      "source": [
        "# Just to let you know for the Future to perform sequence_labels it requires\n",
        "# you to tokenize the TargetTextCollection first\n",
        "for name, dataset in name_dataset:\n",
        "  print(name)\n",
        "  dataset.sequence_labels()\n",
        "sample = rest_target_16_train['1086415:2']\n",
        "print(sample['sequence_labels'])\n",
        "print(sample['tokenized_text'])\n",
        "print(sample['targets'])\n",
        "print(sample['spans'])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Laptop Train\n",
            "Laptop Test\n",
            "Restaurant 14 Train\n",
            "Restaurant 14_Test\n",
            "Restaurant 16 Train\n",
            "Restaurant 16_Test\n",
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "['$', '6', 'and', 'there', 'is', 'much', 'tasty', 'food', ',', 'all', 'of', 'it', 'fresh', 'and', 'continually', 'refilled', '.']\n",
            "['food']\n",
            "[Span(start=27, end=31)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lzx6k0sJa90v",
        "colab_type": "text"
      },
      "source": [
        "Above we have used the Gold Spans to create the sequence labels based on the tokenization and we have printed the sequence labels, tokens, and the Gold Spans and in this case the Spans align perfectly with the tokens. However the assumption I think in the field is that tokenization does not cause any errors but this is not True as not all tokens perfectly align with the Gold Spans an example of this is shown below. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ax0_gUw1fcsm",
        "colab_type": "code",
        "outputId": "7a6a5c90-cf47-4383-e922-52be91eab1da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 271
        }
      },
      "source": [
        "measures = laptop_train.exact_match_score('sequence_labels')\n",
        "recall, precision, f1, errors_analysis = measures\n",
        "print(f'Recall: {recall:.3f}\\nPrecision: {precision:.3f}\\nF1: {f1:.3f}\\n')\n",
        "\n",
        "false_positive_mistakes = errors_analysis['FP']\n",
        "false_negative_mistakes = errors_analysis['FN']\n",
        "print(f'Example of mistake return {false_positive_mistakes[0]}')\n",
        "fp_sample_mistake_id = false_positive_mistakes[0][0]\n",
        "fp_sample_mistake_span = false_positive_mistakes[0][1]\n",
        "\n",
        "fp_sample = laptop_train[fp_sample_mistake_id]\n",
        "incorrect_target = fp_sample['text'][fp_sample_mistake_span.start:fp_sample_mistake_span.end]\n",
        "print(f'FP Mistake using `Golden` sequence labels:\\nText: {fp_sample[\"text\"]}'\n",
        "      f'\\nTokenised Text: {fp_sample[\"tokenized_text\"]}\\n'\n",
        "      f'Gold Sequence Labels: {fp_sample[\"sequence_labels\"]}\\n'\n",
        "      f'Gold Spans: {fp_sample[\"spans\"]}\\nGold Targets: {fp_sample[\"targets\"]}\\n'\n",
        "      f'The Span that is the mistake: {fp_sample_mistake_span}\\n'\n",
        "      f'The Target the incorrect span picked out: {incorrect_target}')"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Recall: 0.997\n",
            "Precision: 0.997\n",
            "F1: 0.997\n",
            "\n",
            "Example of mistake return ('2534', Span(start=57, end=69))\n",
            "FP Mistake using `Golden` sequence labels:\n",
            "Text: But the machine is awesome and iLife is great and I love Snow Leopard X.\n",
            "Tokenised Text: ['But', 'the', 'machine', 'is', 'awesome', 'and', 'i', 'Life', 'is', 'great', 'and', 'I', 'love', 'Snow', 'Leopard', 'X.']\n",
            "Gold Sequence Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O']\n",
            "Gold Spans: [Span(start=31, end=36), Span(start=57, end=71)]\n",
            "Gold Targets: ['iLife', 'Snow Leopard X']\n",
            "The Span that is the mistake: Span(start=57, end=69)\n",
            "The Target the incorrect span picked out: Snow Leopard\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSfWoAz9_Jit",
        "colab_type": "text"
      },
      "source": [
        "We can see why it did not pick out `Snow Leopard X` as a Multi Word Target because the tokenization did not Seperate `X` with the `.` thus `X.` was not labelled and even if it was it would be incorrect as `Snow Leopard X.` is not equal to `Snow Leopard X`\n",
        "\n",
        "Below we show what the true F1 scores are for the different datasets with the three different tokenization methods."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLJAtz7cOU-W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "name_tokenizer = [('Stanford', stanford_tok_en), ('Spacy', spacy_tok_en),\n",
        "                  ('Whitespace', whitespace_tok)]\n",
        "dataset_tokenizer = defaultdict(lambda: {})\n",
        "for dataset_name, dataset in name_dataset:\n",
        "  for tokenizer_name, tokenizer in name_tokenizer:\n",
        "    dataset.tokenize(tokenizer)\n",
        "    dataset.sequence_labels()\n",
        "    measures = dataset.exact_match_score('sequence_labels')\n",
        "    f1 = measures[2]\n",
        "    dataset_tokenizer[dataset_name][tokenizer_name] = f1\n",
        "pd.DataFrame(dataset_tokenizer).T.round(3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3alsem_RzGn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "4136a647-636a-4ca1-d8d0-14053e00130d"
      },
      "source": [
        "pd.DataFrame(dataset_tokenizer).T.round(3)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Spacy</th>\n",
              "      <th>Stanford</th>\n",
              "      <th>Whitespace</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Laptop Train</th>\n",
              "      <td>0.995</td>\n",
              "      <td>0.997</td>\n",
              "      <td>0.749</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Laptop Test</th>\n",
              "      <td>0.993</td>\n",
              "      <td>0.992</td>\n",
              "      <td>0.715</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Restaurant 14 Train</th>\n",
              "      <td>0.998</td>\n",
              "      <td>0.999</td>\n",
              "      <td>0.777</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Restaurant 14_Test</th>\n",
              "      <td>0.999</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.727</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Restaurant 16 Train</th>\n",
              "      <td>0.998</td>\n",
              "      <td>0.999</td>\n",
              "      <td>0.793</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Restaurant 16_Test</th>\n",
              "      <td>0.995</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.757</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     Spacy  Stanford  Whitespace\n",
              "Laptop Train         0.995     0.997       0.749\n",
              "Laptop Test          0.993     0.992       0.715\n",
              "Restaurant 14 Train  0.998     0.999       0.777\n",
              "Restaurant 14_Test   0.999     1.000       0.727\n",
              "Restaurant 16 Train  0.998     0.999       0.793\n",
              "Restaurant 16_Test   0.995     1.000       0.757"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBVg5S0TWNX2",
        "colab_type": "text"
      },
      "source": [
        "Above the F1 scores for the different tokenizers of which these sequences would be treated as the Gold Standard Sequences for the machine learning model show very different results between an actual tokenizer and Whitespace. The difference between Stanford and Spacy is marginal"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIxk1Q7ZV2Ys",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}